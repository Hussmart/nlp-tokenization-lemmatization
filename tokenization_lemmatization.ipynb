{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e992c3",
   "metadata": {},
   "source": [
    "#  NLP Tokenization & Lemmatization: NLTK vs spaCy\n",
    "\n",
    "This notebook demonstrates key NLP preprocessing tasks using two popular Python libraries: **NLTK** and **spaCy**.\n",
    "\n",
    "We'll explore:\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Comparison between NLTK and spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b07eb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shirvanit.ir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shirvanit.ir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shirvanit.ir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shirvanit.ir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e3761",
   "metadata": {},
   "source": [
    "##  Load Sample Text\n",
    "\n",
    "We read input text from the `sample.txt` file.\n",
    "Make sure this file exists in the same directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c37113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Sample Text:\n",
      "\n",
      "The striped bats are hanging on their feet for best.\n",
      "He studies all the time, but he studied little yesterday.\n",
      "They're looking for better solutions than what we had.\n",
      "Running faster won't always get you the best results.\n",
      "My friends' bikes were stolen, and the police are investigating.\n",
      "Better tools can be found in newer technologies.\n",
      "I was hoping that better results had been achieved.\n",
      "The children are playing with robotic dogs in the park.\n",
      "He gave better advice than the older advisor.\n",
      "Cats chasing mice is a common cartoon scenario.\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\" Sample Text:\\n\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc498982",
   "metadata": {},
   "source": [
    "##  Tokenization\n",
    "\n",
    "We'll tokenize the text using:\n",
    "- **NLTK**'s `word_tokenize`\n",
    "- **spaCy**'s built-in tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d51e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NLTK Tokens:\n",
      "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best', '.', 'He', 'studies', 'all', 'the', 'time', ',', 'but', 'he', 'studied', 'little', 'yesterday', '.', 'They', \"'re\", 'looking', 'for', 'better', 'solutions', 'than', 'what', 'we', 'had', '.', 'Running', 'faster', 'wo', \"n't\", 'always', 'get', 'you', 'the', 'best', 'results', '.', 'My', 'friends', \"'\", 'bikes', 'were', 'stolen', ',', 'and', 'the', 'police', 'are', 'investigating', '.', 'Better', 'tools', 'can', 'be', 'found', 'in', 'newer', 'technologies', '.', 'I', 'was', 'hoping', 'that', 'better', 'results', 'had', 'been', 'achieved', '.', 'The', 'children', 'are', 'playing', 'with', 'robotic', 'dogs', 'in', 'the', 'park', '.', 'He', 'gave', 'better', 'advice', 'than', 'the', 'older', 'advisor', '.', 'Cats', 'chasing', 'mice', 'is', 'a', 'common', 'cartoon', 'scenario', '.']\n",
      "\n",
      " spaCy Tokens:\n",
      "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best', '.', '\\n', 'He', 'studies', 'all', 'the', 'time', ',', 'but', 'he', 'studied', 'little', 'yesterday', '.', '\\n', 'They', \"'re\", 'looking', 'for', 'better', 'solutions', 'than', 'what', 'we', 'had', '.', '\\n', 'Running', 'faster', 'wo', \"n't\", 'always', 'get', 'you', 'the', 'best', 'results', '.', '\\n', 'My', 'friends', \"'\", 'bikes', 'were', 'stolen', ',', 'and', 'the', 'police', 'are', 'investigating', '.', '\\n', 'Better', 'tools', 'can', 'be', 'found', 'in', 'newer', 'technologies', '.', '\\n', 'I', 'was', 'hoping', 'that', 'better', 'results', 'had', 'been', 'achieved', '.', '\\n', 'The', 'children', 'are', 'playing', 'with', 'robotic', 'dogs', 'in', 'the', 'park', '.', '\\n', 'He', 'gave', 'better', 'advice', 'than', 'the', 'older', 'advisor', '.', '\\n', 'Cats', 'chasing', 'mice', 'is', 'a', 'common', 'cartoon', 'scenario', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# NLTK Tokenization\n",
    "nltk_tokens = word_tokenize(text)\n",
    "print(\"\\n NLTK Tokens:\")\n",
    "print(nltk_tokens)\n",
    "\n",
    "# spaCy Tokenization\n",
    "doc = nlp(text)\n",
    "spacy_tokens = [token.text for token in doc]\n",
    "print(\"\\n spaCy Tokens:\")\n",
    "print(spacy_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ddb6b",
   "metadata": {},
   "source": [
    "##  Stemming (NLTK Only)\n",
    "\n",
    "Stemming reduces a word to its base or root form.\n",
    "We'll compare three stemmers from NLTK:\n",
    "- **Porter**\n",
    "- **Lancaster**\n",
    "- **Snowball**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd55d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Porter         Lancaster      Snowball\n",
      "------------------------------------------------------------\n",
      "The            the            the            the\n",
      "striped        stripe         striped        stripe\n",
      "bats           bat            bat            bat\n",
      "are            are            ar             are\n",
      "hanging        hang           hang           hang\n",
      "on             on             on             on\n",
      "their          their          their          their\n",
      "feet           feet           feet           feet\n",
      "for            for            for            for\n",
      "best           best           best           best\n",
      "He             he             he             he\n",
      "studies        studi          study          studi\n",
      "all            all            al             all\n",
      "the            the            the            the\n",
      "time           time           tim            time\n",
      "but            but            but            but\n",
      "he             he             he             he\n",
      "studied        studi          study          studi\n",
      "little         littl          littl          littl\n",
      "yesterday      yesterday      yesterday      yesterday\n",
      "They           they           they           they\n",
      "looking        look           look           look\n",
      "for            for            for            for\n",
      "better         better         bet            better\n",
      "solutions      solut          solv           solut\n",
      "than           than           than           than\n",
      "what           what           what           what\n",
      "we             we             we             we\n",
      "had            had            had            had\n",
      "Running        run            run            run\n",
      "faster         faster         fast           faster\n",
      "wo             wo             wo             wo\n",
      "always         alway          alway          alway\n",
      "get            get            get            get\n",
      "you            you            you            you\n",
      "the            the            the            the\n",
      "best           best           best           best\n",
      "results        result         result         result\n",
      "My             my             my             my\n",
      "friends        friend         friend         friend\n",
      "bikes          bike           bik            bike\n",
      "were           were           wer            were\n",
      "stolen         stolen         stol           stolen\n",
      "and            and            and            and\n",
      "the            the            the            the\n",
      "police         polic          pol            polic\n",
      "are            are            ar             are\n",
      "investigating  investig       investig       investig\n",
      "Better         better         bet            better\n",
      "tools          tool           tool           tool\n",
      "can            can            can            can\n",
      "be             be             be             be\n",
      "found          found          found          found\n",
      "in             in             in             in\n",
      "newer          newer          new            newer\n",
      "technologies   technolog      technolog      technolog\n",
      "I              i              i              i\n",
      "was            wa             was            was\n",
      "hoping         hope           hop            hope\n",
      "that           that           that           that\n",
      "better         better         bet            better\n",
      "results        result         result         result\n",
      "had            had            had            had\n",
      "been           been           been           been\n",
      "achieved       achiev         achiev         achiev\n",
      "The            the            the            the\n",
      "children       children       childr         children\n",
      "are            are            ar             are\n",
      "playing        play           play           play\n",
      "with           with           with           with\n",
      "robotic        robot          robot          robot\n",
      "dogs           dog            dog            dog\n",
      "in             in             in             in\n",
      "the            the            the            the\n",
      "park           park           park           park\n",
      "He             he             he             he\n",
      "gave           gave           gav            gave\n",
      "better         better         bet            better\n",
      "advice         advic          adv            advic\n",
      "than           than           than           than\n",
      "the            the            the            the\n",
      "older          older          old            older\n",
      "advisor        advisor        adv            advisor\n",
      "Cats           cat            cat            cat\n",
      "chasing        chase          chas           chase\n",
      "mice           mice           mic            mice\n",
      "is             is             is             is\n",
      "a              a              a              a\n",
      "common         common         common         common\n",
      "cartoon        cartoon        cartoon        cartoon\n",
      "scenario       scenario       scenario       scenario\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "print(f\"{'Word':<15}{'Porter':<15}{'Lancaster':<15}{'Snowball'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for word in nltk_tokens:\n",
    "    if word.isalpha():\n",
    "        print(f\"{word:<15}{porter.stem(word):<15}{lancaster.stem(word):<15}{snowball.stem(word)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b6e90",
   "metadata": {},
   "source": [
    "##  Lemmatization\n",
    "\n",
    "Lemmatization brings a word to its base dictionary form (lemma).  \n",
    "Unlike stemming, it uses context and part-of-speech (POS) information.\n",
    "\n",
    "We'll use:\n",
    "- **NLTK**'s `WordNetLemmatizer`\n",
    "- **spaCy**'s `token.lemma_`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2580c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NLTK Lemmatization:\n",
      "\n",
      "The            The\n",
      "striped        striped\n",
      "bats           bat\n",
      "are            are\n",
      "hanging        hanging\n",
      "on             on\n",
      "their          their\n",
      "feet           foot\n",
      "for            for\n",
      "best           best\n",
      "He             He\n",
      "studies        study\n",
      "all            all\n",
      "the            the\n",
      "time           time\n",
      "but            but\n",
      "he             he\n",
      "studied        studied\n",
      "little         little\n",
      "yesterday      yesterday\n",
      "They           They\n",
      "looking        looking\n",
      "for            for\n",
      "better         better\n",
      "solutions      solution\n",
      "than           than\n",
      "what           what\n",
      "we             we\n",
      "had            had\n",
      "Running        Running\n",
      "faster         faster\n",
      "wo             wo\n",
      "always         always\n",
      "get            get\n",
      "you            you\n",
      "the            the\n",
      "best           best\n",
      "results        result\n",
      "My             My\n",
      "friends        friend\n",
      "bikes          bike\n",
      "were           were\n",
      "stolen         stolen\n",
      "and            and\n",
      "the            the\n",
      "police         police\n",
      "are            are\n",
      "investigating  investigating\n",
      "Better         Better\n",
      "tools          tool\n",
      "can            can\n",
      "be             be\n",
      "found          found\n",
      "in             in\n",
      "newer          newer\n",
      "technologies   technology\n",
      "I              I\n",
      "was            wa\n",
      "hoping         hoping\n",
      "that           that\n",
      "better         better\n",
      "results        result\n",
      "had            had\n",
      "been           been\n",
      "achieved       achieved\n",
      "The            The\n",
      "children       child\n",
      "are            are\n",
      "playing        playing\n",
      "with           with\n",
      "robotic        robotic\n",
      "dogs           dog\n",
      "in             in\n",
      "the            the\n",
      "park           park\n",
      "He             He\n",
      "gave           gave\n",
      "better         better\n",
      "advice         advice\n",
      "than           than\n",
      "the            the\n",
      "older          older\n",
      "advisor        advisor\n",
      "Cats           Cats\n",
      "chasing        chasing\n",
      "mice           mouse\n",
      "is             is\n",
      "a              a\n",
      "common         common\n",
      "cartoon        cartoon\n",
      "scenario       scenario\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(\" NLTK Lemmatization:\\n\")\n",
    "\n",
    "for word in nltk_tokens:\n",
    "    if word.isalpha():\n",
    "        print(f\"{word:<15}{lemmatizer.lemmatize(word)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c1010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spaCy Lemmatization:\n",
      "\n",
      "The            the\n",
      "striped        striped\n",
      "bats           bat\n",
      "are            be\n",
      "hanging        hang\n",
      "on             on\n",
      "their          their\n",
      "feet           foot\n",
      "for            for\n",
      "best           good\n",
      "He             he\n",
      "studies        study\n",
      "all            all\n",
      "the            the\n",
      "time           time\n",
      "but            but\n",
      "he             he\n",
      "studied        study\n",
      "little         little\n",
      "yesterday      yesterday\n",
      "They           they\n",
      "looking        look\n",
      "for            for\n",
      "better         well\n",
      "solutions      solution\n",
      "than           than\n",
      "what           what\n",
      "we             we\n",
      "had            have\n",
      "Running        run\n",
      "faster         fast\n",
      "wo             will\n",
      "always         always\n",
      "get            get\n",
      "you            you\n",
      "the            the\n",
      "best           good\n",
      "results        result\n",
      "My             my\n",
      "friends        friend\n",
      "bikes          bike\n",
      "were           be\n",
      "stolen         steal\n",
      "and            and\n",
      "the            the\n",
      "police         police\n",
      "are            be\n",
      "investigating  investigate\n",
      "Better         well\n",
      "tools          tool\n",
      "can            can\n",
      "be             be\n",
      "found          find\n",
      "in             in\n",
      "newer          new\n",
      "technologies   technology\n",
      "I              I\n",
      "was            be\n",
      "hoping         hope\n",
      "that           that\n",
      "better         well\n",
      "results        result\n",
      "had            have\n",
      "been           be\n",
      "achieved       achieve\n",
      "The            the\n",
      "children       child\n",
      "are            be\n",
      "playing        play\n",
      "with           with\n",
      "robotic        robotic\n",
      "dogs           dog\n",
      "in             in\n",
      "the            the\n",
      "park           park\n",
      "He             he\n",
      "gave           give\n",
      "better         well\n",
      "advice         advice\n",
      "than           than\n",
      "the            the\n",
      "older          old\n",
      "advisor        advisor\n",
      "Cats           cat\n",
      "chasing        chase\n",
      "mice           mouse\n",
      "is             be\n",
      "a              a\n",
      "common         common\n",
      "cartoon        cartoon\n",
      "scenario       scenario\n"
     ]
    }
   ],
   "source": [
    "print(\" spaCy Lemmatization:\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_alpha:\n",
    "        print(f\"{token.text:<15}{token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a109826",
   "metadata": {},
   "source": [
    "##  Final Comparison\n",
    "\n",
    "| Feature          | NLTK                            | spaCy                          |\n",
    "|------------------|----------------------------------|--------------------------------|\n",
    "| **Tokenization** | Rule-based                      | Rule-based + Statistical       |\n",
    "| **Stemming**     | Porter, Lancaster, Snowball     |  Not Supported                |\n",
    "| **Lemmatization**| WordNet-based (limited context) | POS-aware and context-sensitive |\n",
    "| **Ease of Use**  | Modular                         | Built-in NLP pipeline          |\n",
    "\n",
    " **Conclusion**:  \n",
    "For advanced lemmatization and real-world usage, **spaCy** is typically more powerful and context-aware than **NLTK**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
